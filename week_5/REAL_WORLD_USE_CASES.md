# üåç Real-World Use Cases: Goroutines & Channels

## –ö–æ–ª–∏ —ñ –¥–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å—Å—è Goroutines —Ç–∞ Channels –≤ Production

–¶–µ–π –¥–æ–∫—É–º–µ–Ω—Ç –ø–æ–∫–∞–∑—É—î **20 —Ä–µ–∞–ª—å–Ω–∏—Ö —Å—Ü–µ–Ω–∞—Ä—ñ—ó–≤** –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è goroutines —Ç–∞ channels —É –≤–∏—Ä–æ–±–Ω–∏—á–∏—Ö –∑–∞—Å—Ç–æ—Å—É–Ω–∫–∞—Ö.

---

## üìä –ö–∞—Ç–µ–≥–æ—Ä—ñ—ó Use Cases

1. [HTTP Servers & APIs](#1-http-servers--apis) (5 cases)
2. [Data Processing & Pipelines](#2-data-processing--pipelines) (4 cases)
3. [Background Jobs & Workers](#3-background-jobs--workers) (3 cases)
4. [Real-time Systems](#4-real-time-systems) (3 cases)
5. [Infrastructure & DevOps](#5-infrastructure--devops) (3 cases)
6. [Distributed Systems](#6-distributed-systems) (2 cases)

---

## 1. HTTP Servers & APIs

### üîπ Case 1: HTTP Server –∑ Graceful Shutdown

**–ü—Ä–æ–±–ª–µ–º–∞:** HTTP —Å–µ—Ä–≤–µ—Ä –ø–æ–≤–∏–Ω–µ–Ω –∫–æ—Ä–µ–∫—Ç–Ω–æ –∑–∞–≤–µ—Ä—à–∏—Ç–∏—Å—å –ø—Ä–∏ Ctrl+C, –¥–æ—á–µ–∫–∞–≤—à–∏—Å—å –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è –≤—Å—ñ—Ö –ø–æ—Ç–æ—á–Ω–∏—Ö requests.

**–†—ñ—à–µ–Ω–Ω—è:**
```go
func main() {
    srv := &http.Server{Addr: ":8080"}
    
    // Goroutine –¥–ª—è HTTP server
    go func() {
        if err := srv.ListenAndServe(); err != http.ErrServerClosed {
            log.Fatal(err)
        }
    }()
    
    // Signal handling
    sigChan := make(chan os.Signal, 1)
    signal.Notify(sigChan, syscall.SIGINT, syscall.SIGTERM)
    <-sigChan
    
    // Graceful shutdown
    ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
    defer cancel()
    srv.Shutdown(ctx)
}
```

**–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:**
- ‚úÖ –í—Å—ñ web servers (Gin, Echo, Fiber, net/http)
- ‚úÖ Microservices
- ‚úÖ REST APIs

---

### üîπ Case 2: –ü–∞—Ä–∞–ª–µ–ª—å–Ω—ñ HTTP Requests (Fan-Out)

**–ü—Ä–æ–±–ª–µ–º–∞:** –ü–æ—Ç—Ä—ñ–±–Ω–æ –∑—Ä–æ–±–∏—Ç–∏ 10 HTTP requests –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ —ñ –∑—ñ–±—Ä–∞—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏.

**–†—ñ—à–µ–Ω–Ω—è:**
```go
type Result struct {
    URL      string
    Response *http.Response
    Error    error
}

func fetchURLs(urls []string) []Result {
    results := make(chan Result, len(urls))
    var wg sync.WaitGroup
    
    for _, url := range urls {
        wg.Add(1)
        go func(u string) {
            defer wg.Done()
            resp, err := http.Get(u)
            results <- Result{URL: u, Response: resp, Error: err}
        }(url)
    }
    
    go func() {
        wg.Wait()
        close(results)
    }()
    
    var collected []Result
    for r := range results {
        collected = append(collected, r)
    }
    return collected
}
```

**–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:**
- ‚úÖ Aggregation APIs (–∑–±–∏—Ä–∞—é—Ç—å –¥–∞–Ω—ñ –∑ –∫—ñ–ª—å–∫–æ—Ö –¥–∂–µ—Ä–µ–ª)
- ‚úÖ Health check systems (–ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∫—ñ–ª—å–∫–æ—Ö endpoints)
- ‚úÖ Web scrapers
- ‚úÖ API gateways

**–†–µ–∞–ª—å–Ω—ñ –ø—Ä–æ–µ–∫—Ç–∏:**
- Kubernetes health checks
- Prometheus scraping targets
- GraphQL resolvers (parallel field resolution)

---

### üîπ Case 3: Rate Limiting –¥–ª—è API

**–ü—Ä–æ–±–ª–µ–º–∞:** –û–±–º–µ–∂–∏—Ç–∏ –∫—ñ–ª—å–∫—ñ—Å—Ç—å requests –¥–æ –∑–æ–≤–Ω—ñ—à–Ω—å–æ–≥–æ API (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, 100 req/sec).

**–†—ñ—à–µ–Ω–Ω—è:**
```go
type RateLimiter struct {
    ticker   *time.Ticker
    requests chan struct{}
}

func NewRateLimiter(rps int) *RateLimiter {
    rl := &RateLimiter{
        ticker:   time.NewTicker(time.Second / time.Duration(rps)),
        requests: make(chan struct{}, rps),
    }
    
    go func() {
        for range rl.ticker.C {
            select {
            case rl.requests <- struct{}{}:
            default:
            }
        }
    }()
    
    return rl
}

func (rl *RateLimiter) Wait() {
    <-rl.requests
}

// –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:
limiter := NewRateLimiter(100)
for _, item := range items {
    limiter.Wait()
    go processItem(item)
}
```

**–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:**
- ‚úÖ API clients (Twitter, GitHub, Stripe APIs)
- ‚úÖ Database connection pools
- ‚úÖ External service integrations

**–†–µ–∞–ª—å–Ω—ñ –ø—Ä–æ–µ–∫—Ç–∏:**
- GitHub API client (5000 req/hour limit)
- AWS SDK (service-specific limits)
- Redis rate limiters

---

### üîπ Case 4: Request Timeout –∑ Context

**–ü—Ä–æ–±–ª–µ–º–∞:** HTTP request –Ω–µ –ø–æ–≤–∏–Ω–µ–Ω –≤–∏–∫–æ–Ω—É–≤–∞—Ç–∏—Å—å –¥–æ–≤—à–µ 5 —Å–µ–∫—É–Ω–¥.

**–†—ñ—à–µ–Ω–Ω—è:**
```go
func makeRequest(url string) (*http.Response, error) {
    ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
    defer cancel()
    
    req, err := http.NewRequestWithContext(ctx, "GET", url, nil)
    if err != nil {
        return nil, err
    }
    
    return http.DefaultClient.Do(req)
}
```

**–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:**
- ‚úÖ HTTP clients –∑ timeout
- ‚úÖ Database queries –∑ timeout
- ‚úÖ gRPC calls –∑ deadline
- ‚úÖ Microservice communication

---

### üîπ Case 5: WebSocket Broadcasting

**–ü—Ä–æ–±–ª–µ–º–∞:** –í—ñ–¥–ø—Ä–∞–≤–∏—Ç–∏ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –≤—Å—ñ–º –ø—ñ–¥–∫–ª—é—á–µ–Ω–∏–º WebSocket clients.

**–†—ñ—à–µ–Ω–Ω—è:**
```go
type Hub struct {
    clients    map[*Client]bool
    broadcast  chan []byte
    register   chan *Client
    unregister chan *Client
}

func (h *Hub) run() {
    for {
        select {
        case client := <-h.register:
            h.clients[client] = true
            
        case client := <-h.unregister:
            delete(h.clients, client)
            close(client.send)
            
        case message := <-h.broadcast:
            for client := range h.clients {
                select {
                case client.send <- message:
                default:
                    close(client.send)
                    delete(h.clients, client)
                }
            }
        }
    }
}
```

**–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:**
- ‚úÖ Chat applications (Slack, Discord)
- ‚úÖ Real-time dashboards (Grafana, Datadog)
- ‚úÖ Live notifications
- ‚úÖ Multiplayer games

**–†–µ–∞–ª—å–Ω—ñ –ø—Ä–æ–µ–∫—Ç–∏:**
- Gorilla WebSocket
- Centrifugo (real-time messaging)

---

## 2. Data Processing & Pipelines

### üîπ Case 6: ETL Pipeline (Extract-Transform-Load)

**–ü—Ä–æ–±–ª–µ–º–∞:** –û–±—Ä–æ–±–∏—Ç–∏ –º—ñ–ª—å–π–æ–Ω–∏ records: —á–∏—Ç–∞—Ç–∏ –∑ DB ‚Üí transform ‚Üí –∑–∞–ø–∏—Å–∞—Ç–∏ –≤ —ñ–Ω—à—É DB.

**–†—ñ—à–µ–Ω–Ω—è:**
```go
func ETLPipeline(ctx context.Context) {
    // Stage 1: Extract (read from DB)
    records := extract(ctx, db)
    
    // Stage 2: Transform (process data)
    transformed := transform(ctx, records)
    
    // Stage 3: Load (write to DB)
    load(ctx, transformedDB, transformed)
}

func extract(ctx context.Context, db *sql.DB) <-chan Record {
    out := make(chan Record)
    go func() {
        defer close(out)
        rows, _ := db.QueryContext(ctx, "SELECT * FROM source")
        defer rows.Close()
        
        for rows.Next() {
            var r Record
            rows.Scan(&r.ID, &r.Data)
            select {
            case out <- r:
            case <-ctx.Done():
                return
            }
        }
    }()
    return out
}

func transform(ctx context.Context, in <-chan Record) <-chan Record {
    out := make(chan Record)
    const numWorkers = 10
    var wg sync.WaitGroup
    
    for i := 0; i < numWorkers; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            for record := range in {
                // Transform logic
                record.Data = process(record.Data)
                select {
                case out <- record:
                case <-ctx.Done():
                    return
                }
            }
        }()
    }
    
    go func() {
        wg.Wait()
        close(out)
    }()
    return out
}
```

**–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:**
- ‚úÖ Data warehouses (Snowflake, BigQuery)
- ‚úÖ Data migration tools
- ‚úÖ Log aggregation systems
- ‚úÖ Analytics pipelines

**–†–µ–∞–ª—å–Ω—ñ –ø—Ä–æ–µ–∫—Ç–∏:**
- Apache Kafka consumers
- Airflow tasks (–Ω–∞–ø–∏—Å–∞–Ω—ñ –Ω–∞ Go)
- Custom ETL tools

---

### üîπ Case 7: Image Processing Pipeline

**–ü—Ä–æ–±–ª–µ–º–∞:** –û–±—Ä–æ–±–∏—Ç–∏ 10,000 images: resize ‚Üí compress ‚Üí upload to S3.

**–†—ñ—à–µ–Ω–Ω—è:**
```go
func processImages(images []string) {
    const numWorkers = 20
    jobs := make(chan string, len(images))
    results := make(chan Result, len(images))
    
    // Workers
    for w := 0; w < numWorkers; w++ {
        go func() {
            for imagePath := range jobs {
                // Resize
                img := resize(imagePath)
                // Compress
                compressed := compress(img)
                // Upload
                url := uploadToS3(compressed)
                results <- Result{Path: imagePath, URL: url}
            }
        }()
    }
    
    // Send jobs
    for _, img := range images {
        jobs <- img
    }
    close(jobs)
    
    // Collect results
    for i := 0; i < len(images); i++ {
        <-results
    }
}
```

**–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:**
- ‚úÖ Image CDNs (Cloudinary, Imgix)
- ‚úÖ Video processing (thumbnail generation)
- ‚úÖ PDF generation services
- ‚úÖ Document conversion tools

---

### üîπ Case 8: Log Processing –∑ Buffer

**–ü—Ä–æ–±–ª–µ–º–∞:** –ó—ñ–±—Ä–∞—Ç–∏ 1000 log messages –≤ batch –ø–µ—Ä–µ–¥ –≤—ñ–¥–ø—Ä–∞–≤–∫–æ—é –≤ Elasticsearch.

**–†—ñ—à–µ–Ω–Ω—è:**
```go
type LogBatcher struct {
    logs   chan LogEntry
    batch  []LogEntry
    size   int
    ticker *time.Ticker
}

func (lb *LogBatcher) Start() {
    go func() {
        for {
            select {
            case log := <-lb.logs:
                lb.batch = append(lb.batch, log)
                if len(lb.batch) >= lb.size {
                    lb.flush()
                }
            case <-lb.ticker.C:
                if len(lb.batch) > 0 {
                    lb.flush()
                }
            }
        }
    }()
}

func (lb *LogBatcher) flush() {
    sendToElasticsearch(lb.batch)
    lb.batch = lb.batch[:0]
}
```

**–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:**
- ‚úÖ Logging systems (Logrus, Zap)
- ‚úÖ Metrics aggregation (Prometheus)
- ‚úÖ Event streaming (Kafka producers)
- ‚úÖ Analytics tracking

**–†–µ–∞–ª—å–Ω—ñ –ø—Ä–æ–µ–∫—Ç–∏:**
- Fluentd/Fluent Bit (log forwarders)
- Beats (Elastic stack)
- Vector (observability data pipeline)

---

### üîπ Case 9: CSV File Processing

**–ü—Ä–æ–±–ª–µ–º–∞:** –û–±—Ä–æ–±–∏—Ç–∏ –≤–µ–ª–∏–∫–∏–π CSV —Ñ–∞–π–ª (100GB) –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ.

**–†—ñ—à–µ–Ω–Ω—è:**
```go
func processCSV(filename string) {
    file, _ := os.Open(filename)
    defer file.Close()
    
    scanner := bufio.NewScanner(file)
    lines := make(chan string, 100)
    results := make(chan Result, 100)
    
    // Readers
    go func() {
        for scanner.Scan() {
            lines <- scanner.Text()
        }
        close(lines)
    }()
    
    // Workers
    var wg sync.WaitGroup
    for w := 0; w < 10; w++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            for line := range lines {
                result := processLine(line)
                results <- result
            }
        }()
    }
    
    go func() {
        wg.Wait()
        close(results)
    }()
    
    // Writer
    for result := range results {
        writeToDatabase(result)
    }
}
```

**–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:**
- ‚úÖ Data import tools
- ‚úÖ Batch processing systems
- ‚úÖ Financial reporting
- ‚úÖ Data analysis tools

---

## 3. Background Jobs & Workers

### üîπ Case 10: Job Queue –∑ Priority

**–ü—Ä–æ–±–ª–µ–º–∞:** –û–±—Ä–æ–±–ª—è—Ç–∏ jobs –∑ —Ä—ñ–∑–Ω–∏–º–∏ –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç–∞–º–∏ (high, medium, low).

**–†—ñ—à–µ–Ω–Ω—è:**
```go
type JobQueue struct {
    high   chan Job
    medium chan Job
    low    chan Job
}

func (jq *JobQueue) worker(id int) {
    for {
        select {
        case job := <-jq.high:
            fmt.Printf("Worker %d: processing HIGH priority job\n", id)
            process(job)
        case job := <-jq.medium:
            fmt.Printf("Worker %d: processing MEDIUM priority job\n", id)
            process(job)
        case job := <-jq.low:
            fmt.Printf("Worker %d: processing LOW priority job\n", id)
            process(job)
        }
    }
}
```

**–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:**
- ‚úÖ Background job processors (Sidekiq equivalent in Go)
- ‚úÖ Task schedulers
- ‚úÖ Email sending queues
- ‚úÖ Notification systems

**–†–µ–∞–ª—å–Ω—ñ –ø—Ä–æ–µ–∫—Ç–∏:**
- Asynq (distributed task queue)
- Machinery (async task queue)
- RiverQueue

---

### üîπ Case 11: Scheduled Tasks (Cron Jobs)

**–ü—Ä–æ–±–ª–µ–º–∞:** –í–∏–∫–æ–Ω—É–≤–∞—Ç–∏ tasks –∫–æ–∂–Ω—ñ 5 —Ö–≤–∏–ª–∏–Ω (cleanup, reports, backups).

**–†—ñ—à–µ–Ω–Ω—è:**
```go
type Scheduler struct {
    tasks map[string]*ScheduledTask
    stop  chan bool
}

type ScheduledTask struct {
    Name     string
    Interval time.Duration
    Task     func()
}

func (s *Scheduler) Start() {
    for _, task := range s.tasks {
        go func(t *ScheduledTask) {
            ticker := time.NewTicker(t.Interval)
            defer ticker.Stop()
            
            for {
                select {
                case <-ticker.C:
                    t.Task()
                case <-s.stop:
                    return
                }
            }
        }(task)
    }
}

// –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:
scheduler.AddTask("cleanup", 5*time.Minute, cleanupOldFiles)
scheduler.AddTask("backup", 1*time.Hour, backupDatabase)
scheduler.Start()
```

**–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:**
- ‚úÖ Database cleanup tasks
- ‚úÖ Report generation
- ‚úÖ Cache invalidation
- ‚úÖ Health checks

**–†–µ–∞–ª—å–Ω—ñ –ø—Ä–æ–µ–∫—Ç–∏:**
- Kubernetes CronJobs
- Nomad periodic jobs
- Custom schedulers

---

### üîπ Case 12: Email Sending Queue

**–ü—Ä–æ–±–ª–µ–º–∞:** –í—ñ–¥–ø—Ä–∞–≤–∏—Ç–∏ 10,000 emails –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –∑ retry –ª–æ–≥—ñ–∫–æ—é.

**–†—ñ—à–µ–Ω–Ω—è:**
```go
type EmailQueue struct {
    emails  chan Email
    results chan EmailResult
    workers int
}

func (eq *EmailQueue) Start() {
    for w := 0; w < eq.workers; w++ {
        go func(id int) {
            for email := range eq.emails {
                err := sendEmail(email)
                if err != nil && shouldRetry(err) {
                    // Retry logic
                    time.Sleep(1 * time.Second)
                    eq.emails <- email // Re-queue
                } else {
                    eq.results <- EmailResult{
                        Email: email,
                        Error: err,
                    }
                }
            }
        }(w)
    }
}
```

**–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:**
- ‚úÖ Transactional emails (order confirmations)
- ‚úÖ Marketing campaigns
- ‚úÖ Password reset emails
- ‚úÖ Notification systems

**–†–µ–∞–ª—å–Ω—ñ –ø—Ä–æ–µ–∫—Ç–∏:**
- Mailgun queue
- SendGrid batch processing
- AWS SES with SQS

---

## 4. Real-time Systems

### üîπ Case 13: Server-Sent Events (SSE) Broadcasting

**–ü—Ä–æ–±–ª–µ–º–∞:** –í—ñ–¥–ø—Ä–∞–≤–ª—è—Ç–∏ real-time updates –∫–ª—ñ—î–Ω—Ç–∞–º (live scores, stock prices).

**–†—ñ—à–µ–Ω–Ω—è:**
```go
type SSEServer struct {
    clients  map[chan string]bool
    addCh    chan chan string
    removeCh chan chan string
    broadcast chan string
}

func (s *SSEServer) Run() {
    go func() {
        for {
            select {
            case client := <-s.addCh:
                s.clients[client] = true
            case client := <-s.removeCh:
                delete(s.clients, client)
                close(client)
            case msg := <-s.broadcast:
                for client := range s.clients {
                    select {
                    case client <- msg:
                    default:
                        // Client slow/disconnected
                        delete(s.clients, client)
                        close(client)
                    }
                }
            }
        }
    }()
}
```

**–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:**
- ‚úÖ Live sports scores
- ‚úÖ Stock tickers
- ‚úÖ Real-time dashboards
- ‚úÖ Live auction systems

---

### üîπ Case 14: Metrics Collection System

**–ü—Ä–æ–±–ª–µ–º–∞:** –ó–±–∏—Ä–∞—Ç–∏ metrics –∑ 1000 servers –∫–æ–∂–Ω—ñ 10 —Å–µ–∫—É–Ω–¥.

**–†—ñ—à–µ–Ω–Ω—è:**
```go
type MetricsCollector struct {
    servers []Server
    metrics chan Metric
}

func (mc *MetricsCollector) Start() {
    ticker := time.NewTicker(10 * time.Second)
    
    go func() {
        for range ticker.C {
            var wg sync.WaitGroup
            for _, server := range mc.servers {
                wg.Add(1)
                go func(s Server) {
                    defer wg.Done()
                    metric := s.CollectMetrics()
                    mc.metrics <- metric
                }(server)
            }
        }
    }()
    
    // Processor
    go func() {
        for metric := range mc.metrics {
            storeInDB(metric)
            checkAlerts(metric)
        }
    }()
}
```

**–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:**
- ‚úÖ Monitoring systems (Prometheus, Datadog)
- ‚úÖ APM tools (New Relic, AppDynamics)
- ‚úÖ Infrastructure monitoring
- ‚úÖ Application metrics

**–†–µ–∞–ª—å–Ω—ñ –ø—Ä–æ–µ–∫—Ç–∏:**
- Prometheus exporters
- Telegraf plugins
- Custom monitoring agents

---

### üîπ Case 15: Event Sourcing System

**–ü—Ä–æ–±–ª–µ–º–∞:** –û–±—Ä–æ–±–ª—è—Ç–∏ events –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ —ñ –∞–ø–¥–µ–π—Ç–∏—Ç–∏ read models.

**–†—ñ—à–µ–Ω–Ω—è:**
```go
type EventStore struct {
    events     chan Event
    projectors []Projector
}

func (es *EventStore) Start() {
    // Fan-out: –æ–¥–∏–Ω event ‚Üí –∫—ñ–ª—å–∫–∞ projectors
    for _, projector := range es.projectors {
        go func(p Projector) {
            for event := range es.events {
                p.Project(event)
            }
        }(projector)
    }
}

// –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:
eventStore := NewEventStore()
eventStore.AddProjector(&UserProjector{})
eventStore.AddProjector(&OrderProjector{})
eventStore.AddProjector(&AnalyticsProjector{})
eventStore.Start()

// Publish event
eventStore.Publish(OrderCreatedEvent{OrderID: 123})
```

**–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:**
- ‚úÖ CQRS systems
- ‚úÖ Event-driven architectures
- ‚úÖ Audit logging
- ‚úÖ Microservices communication

---

## 5. Infrastructure & DevOps

### üîπ Case 16: Health Check System

**–ü—Ä–æ–±–ª–µ–º–∞:** –ü–µ—Ä–µ–≤—ñ—Ä—è—Ç–∏ health 50 microservices –∫–æ–∂–Ω—ñ 30 —Å–µ–∫—É–Ω–¥.

**–†—ñ—à–µ–Ω–Ω—è:**
```go
type HealthChecker struct {
    services []Service
    results  chan HealthResult
}

func (hc *HealthChecker) Start() {
    ticker := time.NewTicker(30 * time.Second)
    
    go func() {
        for range ticker.C {
            var wg sync.WaitGroup
            for _, service := range hc.services {
                wg.Add(1)
                go func(s Service) {
                    defer wg.Done()
                    
                    ctx, cancel := context.WithTimeout(
                        context.Background(), 
                        5*time.Second,
                    )
                    defer cancel()
                    
                    healthy := s.CheckHealth(ctx)
                    hc.results <- HealthResult{
                        Service: s.Name,
                        Healthy: healthy,
                        Time:    time.Now(),
                    }
                }(service)
            }
        }
    }()
}
```

**–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:**
- ‚úÖ Kubernetes liveness/readiness probes
- ‚úÖ Load balancer health checks
- ‚úÖ Service mesh (Istio, Linkerd)
- ‚úÖ Monitoring dashboards

---

### üîπ Case 17: Distributed Cache Warming

**–ü—Ä–æ–±–ª–µ–º–∞:** –ü—Ä–æ–≥—Ä—ñ—Ç–∏ cache –Ω–∞ 20 servers –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ –ø—ñ—Å–ª—è deploy.

**–†—ñ—à–µ–Ω–Ω—è:**
```go
func warmupCache(servers []string, data []CacheEntry) {
    var wg sync.WaitGroup
    
    for _, server := range servers {
        wg.Add(1)
        go func(s string) {
            defer wg.Done()
            
            client := redis.NewClient(&redis.Options{Addr: s})
            for _, entry := range data {
                client.Set(entry.Key, entry.Value, entry.TTL)
            }
        }(server)
    }
    
    wg.Wait()
    log.Println("Cache warmed up on all servers")
}
```

**–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:**
- ‚úÖ CDN cache warming
- ‚úÖ Redis/Memcached warming
- ‚úÖ Application cache initialization
- ‚úÖ Deployment automation

---

### üîπ Case 18: Log Aggregation System

**–ü—Ä–æ–±–ª–µ–º–∞:** –ó–±–∏—Ä–∞—Ç–∏ logs –∑ 100 pods –≤ Kubernetes cluster.

**–†—ñ—à–µ–Ω–Ω—è:**
```go
type LogAggregator struct {
    pods    []Pod
    logs    chan LogEntry
    storage LogStorage
}

func (la *LogAggregator) Start() {
    // Tail logs from each pod
    for _, pod := range la.pods {
        go func(p Pod) {
            stream := p.StreamLogs()
            for log := range stream {
                la.logs <- LogEntry{
                    Pod:       p.Name,
                    Timestamp: time.Now(),
                    Message:   log,
                }
            }
        }(pod)
    }
    
    // Batch writer
    go func() {
        batch := make([]LogEntry, 0, 1000)
        ticker := time.NewTicker(5 * time.Second)
        
        for {
            select {
            case log := <-la.logs:
                batch = append(batch, log)
                if len(batch) >= 1000 {
                    la.storage.WriteBatch(batch)
                    batch = batch[:0]
                }
            case <-ticker.C:
                if len(batch) > 0 {
                    la.storage.WriteBatch(batch)
                    batch = batch[:0]
                }
            }
        }
    }()
}
```

**–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:**
- ‚úÖ ELK stack (Elasticsearch, Logstash, Kibana)
- ‚úÖ Grafana Loki
- ‚úÖ Splunk
- ‚úÖ Custom log aggregators

---

## 6. Distributed Systems

### üîπ Case 19: Distributed Task Execution

**–ü—Ä–æ–±–ª–µ–º–∞:** –í–∏–∫–æ–Ω–∞—Ç–∏ task –Ω–∞ 10 remote workers —ñ –∑—ñ–±—Ä–∞—Ç–∏ results.

**–†—ñ—à–µ–Ω–Ω—è:**
```go
type DistributedExecutor struct {
    workers []WorkerClient
}

func (de *DistributedExecutor) Execute(task Task) []Result {
    results := make(chan Result, len(de.workers))
    ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
    defer cancel()
    
    var wg sync.WaitGroup
    for _, worker := range de.workers {
        wg.Add(1)
        go func(w WorkerClient) {
            defer wg.Done()
            result, err := w.ExecuteTask(ctx, task)
            if err != nil {
                results <- Result{Error: err, Worker: w.ID}
            } else {
                results <- Result{Data: result, Worker: w.ID}
            }
        }(worker)
    }
    
    go func() {
        wg.Wait()
        close(results)
    }()
    
    var collected []Result
    for r := range results {
        collected = append(collected, r)
    }
    return collected
}
```

**–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:**
- ‚úÖ MapReduce frameworks
- ‚úÖ Distributed computing
- ‚úÖ Grid computing
- ‚úÖ Parallel test execution

**–†–µ–∞–ª—å–Ω—ñ –ø—Ä–æ–µ–∫—Ç–∏:**
- Apache Spark (Go clients)
- Dask (distributed computing)
- Custom distributed systems

---

### üîπ Case 20: Message Queue Consumer (Kafka/RabbitMQ)

**–ü—Ä–æ–±–ª–µ–º–∞:** –°–ø–æ–∂–∏–≤–∞—Ç–∏ messages –∑ Kafka topic –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ.

**–†—ñ—à–µ–Ω–Ω—è:**
```go
type KafkaConsumer struct {
    consumer    *kafka.Consumer
    workers     int
    messages    chan *kafka.Message
    stopCh      chan bool
}

func (kc *KafkaConsumer) Start() {
    // Fetcher: —á–∏—Ç–∞—î messages –∑ Kafka
    go func() {
        for {
            select {
            case <-kc.stopCh:
                return
            default:
                msg, err := kc.consumer.ReadMessage(1 * time.Second)
                if err == nil {
                    kc.messages <- msg
                }
            }
        }
    }()
    
    // Workers: –æ–±—Ä–æ–±–ª—è—é—Ç—å messages –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ
    for w := 0; w < kc.workers; w++ {
        go func(id int) {
            for msg := range kc.messages {
                processMessage(msg)
                kc.consumer.CommitMessages(msg)
            }
        }(w)
    }
}

func (kc *KafkaConsumer) Stop() {
    close(kc.stopCh)
    close(kc.messages)
}
```

**–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è:**
- ‚úÖ Event streaming platforms
- ‚úÖ Message queue consumers
- ‚úÖ Data pipelines
- ‚úÖ Microservices communication

**–†–µ–∞–ª—å–Ω—ñ –ø—Ä–æ–µ–∫—Ç–∏:**
- Kafka Go clients (Sarama, Confluent)
- RabbitMQ Go library (amqp091-go)
- NATS streaming
- Redis Streams consumers

---

## üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è

### –ó–∞ —Ç–∏–ø–æ–º –∑–∞—Å—Ç–æ—Å—É–Ω–∫—É:

| –¢–∏–ø | Use Cases | % |
|-----|-----------|---|
| **Web/API** | 5 | 25% |
| **Data Processing** | 4 | 20% |
| **Background Jobs** | 3 | 15% |
| **Real-time** | 3 | 15% |
| **Infrastructure** | 3 | 15% |
| **Distributed** | 2 | 10% |

### –¢–æ–ø-5 –ø–∞—Ç—Ç–µ—Ä–Ω—ñ–≤:

1. **Worker Pool** (Cases: 2, 6, 7, 9, 10, 12, 20) - **35%**
2. **Fan-Out/Fan-In** (Cases: 2, 14, 15, 19) - **20%**
3. **Pipeline** (Cases: 6, 7, 8, 9) - **20%**
4. **Broadcasting** (Cases: 5, 13, 15) - **15%**
5. **Graceful Shutdown** (Cases: 1, 11, 12, 20) - **20%**

---

## ‚úÖ –ö–æ–ª–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ Goroutines & Channels

### ‚úÖ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –∫–æ–ª–∏:

1. **I/O-bound operations** - HTTP requests, DB queries, file operations
2. **Parallel processing** - –æ–±—Ä–æ–±–∫–∞ –≤–µ–ª–∏–∫–∏—Ö datasets
3. **Real-time systems** - WebSockets, SSE, streaming
4. **Background tasks** - email sending, cleanup, reports
5. **Event-driven architecture** - event sourcing, pub/sub
6. **Distributed systems** - microservices, distributed computing

### ‚ùå –ù–ï –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –∫–æ–ª–∏:

1. **CPU-bound –±–µ–∑ parallelism** - —Å–∫–ª–∞–¥–Ω—ñ –º–∞—Ç–µ–º–∞—Ç–∏—á–Ω—ñ –æ–±—á–∏—Å–ª–µ–Ω–Ω—è (–≤–∏–∫–æ—Ä–∏—Å—Ç–∞–π—Ç–µ GOMAXPROCS)
2. **–ü—Ä–æ—Å—Ç—ñ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ñ –æ–ø–µ—Ä–∞—Ü—ñ—ó** - –Ω–µ –ø–æ—Ç—Ä—ñ–±–Ω–∞ concurrency
3. **–ú–∞–ª–∏–π –æ–±—Å—è–≥ –¥–∞–Ω–∏—Ö** - overhead –º–æ–∂–µ –±—É—Ç–∏ –±—ñ–ª—å—à–∏–º –∑–∞ benefit
4. **–°–∫–ª–∞–¥–Ω–∞ state synchronization** - –º–æ–∂–ª–∏–≤–æ –ø—Ä–æ—Å—Ç—ñ—à–µ single-threaded

---

## üìö –ö–æ—Ä–∏—Å–Ω—ñ —Ä–µ—Å—É—Ä—Å–∏

### Open Source –ø—Ä–æ–µ–∫—Ç–∏ –∑ –≥–∞—Ä–Ω–∏–º–∏ –ø—Ä–∏–∫–ª–∞–¥–∞–º–∏:
- **Docker** - container orchestration
- **Kubernetes** - cluster management
- **Prometheus** - monitoring system
- **InfluxDB** - time-series database
- **CockroachDB** - distributed database
- **NATS** - messaging system
- **Caddy** - web server
- **Traefik** - reverse proxy

### –ö–Ω–∏–≥–∏:
- "Concurrency in Go" by Katherine Cox-Buday
- "Go in Action" by William Kennedy
- "The Go Programming Language" by Alan Donovan

---

## üéØ –í–∏—Å–Ω–æ–≤–æ–∫

**Goroutines —Ç–∞ Channels - —Ü–µ —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç Go –¥–ª—è:**

1. üöÄ **Concurrency** - –ø–∞—Ä–∞–ª–µ–ª—å–Ω–∞ –æ–±—Ä–æ–±–∫–∞
2. üì° **Communication** - –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü—ñ—è –º—ñ–∂ goroutines
3. ‚ö° **Performance** - –µ—Ñ–µ–∫—Ç–∏–≤–Ω–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è —Ä–µ—Å—É—Ä—Å—ñ–≤
4. üé® **Simplicity** - –ø—Ä–æ—Å—Ç–∏–π concurrent code

**–ì–æ–ª–æ–≤–Ω–µ –ø—Ä–∞–≤–∏–ª–æ:**
> "Don't communicate by sharing memory; share memory by communicating."

**–ü—Ä–∞–∫—Ç–∏–∫—É–π—Ç–µ—Å—å –Ω–∞ —Ä–µ–∞–ª—å–Ω–∏—Ö –ø—Ä–æ–µ–∫—Ç–∞—Ö!** üéâ

---

**–°—Ç–≤–æ—Ä–µ–Ω–æ:** 2026-01-15  
**Week 5:** Goroutines & Channels
